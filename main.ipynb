{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ebd54b",
   "metadata": {},
   "source": [
    "# Facebook Comments Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b425d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4a0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_facebook_comments(file_path):\n",
    "    \"\"\"\n",
    "    Processes the raw text from a file containing a copied Facebook post \n",
    "    to extract structured comments into a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the text file containing the copied Facebook data.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing 'Author', 'Comment', and 'Timestamp'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read file content inside the function\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return []\n",
    "\n",
    "    # 1. First try to use the unique repeated \"Facebook\" lines as the start marker.\n",
    "    FACEBOOK_SPAM_BLOCK = \"Facebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\\nFacebook\"\n",
    "    comment_start_index = raw_text.find(FACEBOOK_SPAM_BLOCK)\n",
    "    \n",
    "    if comment_start_index == -1:\n",
    "        # Fallback 1: Try finding \"B√¨nh lu·∫≠n\" after the main post content marker (\"v·∫•n ƒë·ªÅ b·∫£n quy·ªÅn\")\n",
    "        post_content_start_phrase = \"v·∫•n ƒë·ªÅ b·∫£n quy·ªÅn\"\n",
    "        post_start_index = raw_text.find(post_content_start_phrase)\n",
    "        \n",
    "        if post_start_index != -1:\n",
    "            search_area = raw_text[post_start_index:]\n",
    "        else:\n",
    "            search_area = raw_text\n",
    "            \n",
    "        comment_marker_index = search_area.find(\"B√¨nh lu·∫≠n\")\n",
    "        \n",
    "        if comment_marker_index == -1:\n",
    "            print(\"Error: Could not find a reliable start marker for the 'B√¨nh lu·∫≠n' section.\")\n",
    "            return []\n",
    "\n",
    "        absolute_comment_start_index = post_start_index + comment_marker_index\n",
    "        comment_text = raw_text[absolute_comment_start_index + len(\"B√¨nh lu·∫≠n\"):].strip()\n",
    "    else:\n",
    "        # If the new block is found, start immediately after it.\n",
    "        comment_text = raw_text[comment_start_index + len(FACEBOOK_SPAM_BLOCK):].strip()\n",
    "\n",
    "\n",
    "    # 2. Split the text into blocks based on the action buttons or double newlines.\n",
    "    blocks = re.split(r'\\nTr·∫£ l·ªùi\\nChia s·∫ª|\\nTr·∫£ l·ªùi\\n\\n|\\nƒê√£ ch·ªânh s·ª≠a\\nTr·∫£ l·ªùi\\nChia s·∫ª|\\nTr·∫£ l·ªùi\\n|\\nChia s·∫ª', comment_text)\n",
    "    \n",
    "    parsed_comments = []\n",
    "\n",
    "    # 3. Define the core regex pattern for extraction within each block.\n",
    "    comment_pattern = re.compile(\n",
    "        r'(.+?)\\n\\s*'  # 1. Capture Author Name\n",
    "        r'(.+?)'        # 2. Capture Comment Content\n",
    "        r'(\\d+ (?:tu·∫ßn|ng√†y|ph√∫t)|\\d+ (?:gi·ªù|ph√∫t)|\\d+ [0-9]{1,2} [0-9]{4})' # 3. Capture Time/Date\n",
    "        , re.DOTALL\n",
    "    )\n",
    "\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "        \n",
    "        match = comment_pattern.search(block)\n",
    "        \n",
    "        if match:\n",
    "            author_raw = match.group(1).strip()\n",
    "            time_stamp = match.group(3).strip()\n",
    "            content = match.group(2).strip()\n",
    "\n",
    "            # --- Clean-up Steps ---\n",
    "            content = re.sub(r'\\.\\.\\. Xem th√™m', '', content, flags=re.DOTALL).strip()\n",
    "            \n",
    "            author_lines = author_raw.split('\\n')\n",
    "            author = author_lines[0].strip()\n",
    "            \n",
    "            # Remove any special role tags from the author line\n",
    "            author = re.sub(r'Ng∆∞·ªùi ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t|T√°c gi·∫£', '', author).strip()\n",
    "\n",
    "            # Re-join any content that got split into the Author's raw field\n",
    "            if len(author_lines) > 1:\n",
    "                content_start_lines = author_lines[1:]\n",
    "                content = '\\n'.join(content_start_lines) + '\\n' + content\n",
    "                \n",
    "            if len(content) < 5:\n",
    "                continue\n",
    "            \n",
    "            parsed_comments.append({\n",
    "                'Author': author,\n",
    "                'Comment': content,\n",
    "                'Timestamp': time_stamp\n",
    "            })\n",
    "\n",
    "    return parsed_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebfd012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SUCCESSFULLY PARSED COMMENTS ---\n",
      "Total Comments Extracted: 60\n",
      "\n",
      "DataFrame Preview:\n",
      "| Author         | Comment                                                                                                                                                                                                                                                                                                               | Timestamp   |\n",
      "|:---------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------|\n",
      "| Th·∫±ng ƒê·∫ßu L√¨n  | Kh√¥ng ph·ªß nh·∫≠n nhi·ªÅu ƒë·ª©a trong n√†y t·ª´ng coi l·∫≠u nhi·ªÅu k·ªÉ c·∫£ tao h·ªìi ƒë√≥. Gi·ªù l√∫c coi b·ªô manga y√™u th√≠ch n√†o ƒë√≥ t cx mu·ªën mua h√†ng ·ªßng h·ªô t√°c gi·∫£ c∆°                                                                                                                                                                    | 1 tu·∫ßn      |\n",
      "| Quang Ki·ªám     | L·∫≠u l√† l·∫≠u. M√¨nh kh√¥ng c√≥ ti·ªÅn/ƒëi·ªÅu ki·ªán/c√°ch bi·ªát ng√¥n ng·ªØ n√™n m√¨nh ƒë·ªçc l·∫≠u, c·ª© nh·∫≠n th√¥i, c·ª© ph·∫£i v·∫Ω ra l√≠ do l√†m g√¨, ƒë·ªÉ l·∫≠u nh∆∞ng nghe th√¥ng c·∫£m h∆°n √† üòã                                                                                                                                                          | 1 tu·∫ßn      |\n",
      "| Van Anh Pham   | T ch∆°i game l·∫≠u khi ch∆∞a c√≥ ti·ªÅn c√≤n khi c√≥ ƒëi·ªÅu ki·ªán tui mua game tr√™n steam, truy·ªán cx v·∫≠y t mua b·∫£n gi·∫•y c·ªßa n√≥ lu√¥n n·∫øu ƒë√≥ l√† 1 b·ªô tui th√≠ch                                                                                                                                                                      | 1 tu·∫ßn      |\n",
      "| Uy√™n Nh√£       | B·ªè ti·ªÅn ra mua truy·ªán ·ªßng h·ªô b·∫£n quy·ªÅn v√† t·ª´ng b·ªã v√†i ƒë·ª©a ch·ª≠i ngu üòÉ t√≠nh ra nhi·ªÅu ƒë·ª©a ƒë·ªçc l·∫≠u n·∫øt th∆∞·ª£ng ƒë·∫≥ng th·∫≠t ch·ª© b√™n ƒë·ªçc truy·ªán b·∫£n quy·ªÅn th√¨ ch∆∞a th·∫•y gi·ªü gi·ªçng bao gi·ªù                                                                                                                                     | 1 tu·∫ßn      |\n",
      "| Nguy·ªÖn Minh V≈© | Uy√™n Nh√£ ng∆∞·ªùi c√≥ ƒë·ªß c·∫£ ti·ªÅn v√† √Ω th·ª©c ƒë·ªÉ mua h√†ng b·∫£n quy·ªÅn th√¨ t·∫•t nhi√™n ko ƒë·ªß c√°i ngu ƒë·ªÉ th∆∞·ª£ng ƒë·∫≥ng :))                                                                                                                                                                                                           | 6 ng√†y      |\n",
      "| Ph√πng B·∫£o      | ƒê·ªçc l·∫≠u th√¨ c·ª© nh·∫≠n lu√¥n l√† t ngh√®o ho·∫∑c ko ƒëi mua h√†ng th·∫≠t (c√≥ b·∫£n d·ªãch) ƒëc ƒëi, ch·ª© nhi·ªÅu ko hi·ªÉu sao nhi·ªÅu kh·ª©a th·ª±c s·ª± th·ªÉ hi·ªán s·ª± th∆∞·ª£ng ƒë·∫≥ng khi m√¨nh vi ph·∫°m ph√°p lu·∫≠t?                                                                                                                                        | 1 tu·∫ßn      |\n",
      "| ƒê√£ ch·ªânh s·ª≠a   | Phu Khang Tran Ng∆∞·ªùi ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t Ph√πng B·∫£o , ch·∫Øc ch∆∞a? Ch·∫Øc l√† ngh√®o v·ªõi kh√¥ng ƒëi mua h√†ng th·∫≠t ƒë∆∞·ª£c ch∆∞a? C√≥ h√†ng d·ªãch b·∫£n quy·ªÅn kh√¥ng m√† n√≥i n√®?                                                                                                                                                           | 1 tu·∫ßn      |\n",
      "| Ph√πng B·∫£o      | Phu Khang Tran :V Uh th√¨ \"kh√¥ng mua ƒëc h√†ng th·∫≠t\" m·ªü r·ªông th√™m t√≠ nghƒ©a th√¥i, th√†nh \"kh√¥ng mua ƒëc h√†ng th·∫≠t c√≥ b·∫£n d·ªãch\".                                                                                                                                                                                             | 1 tu·∫ßn      |\n",
      "| Phu Khang Tran | Ng∆∞·ªùi ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t Ph√πng B·∫£o , mua b·∫£n g·ªëc Nh·∫≠t, mua b·∫£n d·ªãch Anh, mua b·∫£n d·ªãch Vi·ªát, t√¥i ƒë·ªÅu mua r·ªìi nh√©. Nh∆∞ng r·ªìi nh·ªØng truy·ªán mu·ªën ƒë·ªçc b·∫£n d·ªãch, Anh hay Vi·ªát d·ªãch ch·∫≠m √≠t th√¨ c≈©ng n·ª≠a nƒÉm, nhi·ªÅu c≈©ng 5, 10 nƒÉm. ƒê·ªát. Kh√¥ng xem l·∫≠u v·ªõi mua b·∫£n g·ªëc th√¨ b·∫£n d·ªãch b·∫£n quy·ªÅn c√≥ mo·∫π g√¨ ƒë√¢u m√† l√™n gi·ªçng :V | 1 tu·∫ßn      |\n",
      "| Ph√πng B·∫£o      | Phu Khang Tran Th√¨ t√¥i ƒë√¢u c√≥ n√≥i l√† b·∫£n quy·ªÅn d·ªãch Vi·ªát t·ªët h∆°n ƒë√¢u. T√¥i ch·ªâ n√≥i l·∫≠u th√¨ th√¥i m√¨nh be b√© c√°i mi·ªáng l·∫°i, b·∫£n ch·∫•t vi·ªác m√¨nh l√†m l√† vi ph·∫°m th√¨ n√≥ ch·∫£ c√≥ g√¨ hay ho c·∫£.                                                                                                                                | 1 tu·∫ßn      |\n"
     ]
    }
   ],
   "source": [
    "post1 = parse_facebook_comments('fb_post1.txt')\n",
    "\n",
    "if post1:\n",
    "    df_comments = pd.DataFrame(post1)\n",
    "    \n",
    "    # Final Cleaning\n",
    "    df_comments['Comment'] = df_comments['Comment'].str.replace(r'[\\r\\n\\t]+', ' ', regex=True).str.strip()\n",
    "    df_comments.drop_duplicates(subset=['Comment'], keep='first', inplace=True)\n",
    "    df_comments = df_comments[df_comments['Comment'].str.len() > 10].reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n--- SUCCESSFULLY PARSED COMMENTS ---\")\n",
    "    print(f\"Total Comments Extracted: {len(df_comments)}\")\n",
    "    print(\"\\nDataFrame Preview:\")\n",
    "    print(df_comments.head(10).to_markdown(index=False))\n",
    "    \n",
    "    # Example: Save to CSV\n",
    "    # df_comments.to_csv('cleaned_facebook_comments.csv', index=False, encoding='utf-8')\n",
    "else:\n",
    "    print(\"\\nParsing failed. Please check the content of 'comments.txt' to ensure the structure is consistent.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc99bc3",
   "metadata": {},
   "source": [
    "## Translate to English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e0f00",
   "metadata": {},
   "source": [
    "#### Using Ollama (https://ollama.com/library/llava)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390dbb20",
   "metadata": {},
   "source": [
    "Download the official executable file from https://ollama.com/download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab650f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Install the LLM for Natural LAnguage Processing model locally\n",
    "!ollama pull mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e011e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n"
     ]
    }
   ],
   "source": [
    "# Check if Ollama is running, should be error:  address already in use\n",
    "!ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0868fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE_NAME = 'comments.txt'\n",
    "OLLAMA_API_URL = 'http://localhost:11434/api/generate'\n",
    "OLLAMA_MODEL = 'llama3' \n",
    "\n",
    "def translate_text_with_ollama(text):\n",
    "    \"\"\"\n",
    "    Sends text to the local Ollama Llama 3 API for translation.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The Vietnamese text to translate.\n",
    "        \n",
    "    Returns:\n",
    "        str: The English translation or an error message.\n",
    "    \"\"\"\n",
    "    if not text or len(text.strip()) < 5:\n",
    "        return \"\"\n",
    "\n",
    "    # prompt = f\"Translate the following Vietnamese social media comment to natural, modern English. Be concise and provide only the translated text: {text}\"\n",
    "    prompt = f\"Translate the following Vietnamese text to English, provides only the translated text: {text}\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.1 # Low temperature for accurate, literal translation\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Ollama returns a JSON response; the generated text is under 'response'\n",
    "        data = response.json()\n",
    "        translated_text = data.get('response', '').strip()\n",
    "        \n",
    "        # Clean up common LLM output formatting (like unnecessary quotes or labels)\n",
    "        if translated_text.startswith(('\"', \"'\")) and translated_text.endswith(('\"', \"'\")):\n",
    "            translated_text = translated_text[1:-1]\n",
    "        \n",
    "        return translated_text\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"ERROR: Ollama API Timeout\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"ERROR: Ollama connection failed or server error. Check if Ollama is running: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: Unknown API issue: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2a52402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Kh√¥ng ph·ªß nh·∫≠n nhi·ªÅu ƒë·ª©a trong n√†y t·ª´ng coi l·∫≠...\n",
       "1     L·∫≠u l√† l·∫≠u. M√¨nh kh√¥ng c√≥ ti·ªÅn/ƒëi·ªÅu ki·ªán/c√°ch ...\n",
       "2     T ch∆°i game l·∫≠u khi ch∆∞a c√≥ ti·ªÅn c√≤n khi c√≥ ƒëi...\n",
       "3     B·ªè ti·ªÅn ra mua truy·ªán ·ªßng h·ªô b·∫£n quy·ªÅn v√† t·ª´ng...\n",
       "4     Uy√™n Nh√£ ng∆∞·ªùi c√≥ ƒë·ªß c·∫£ ti·ªÅn v√† √Ω th·ª©c ƒë·ªÉ mua ...\n",
       "5     ƒê·ªçc l·∫≠u th√¨ c·ª© nh·∫≠n lu√¥n l√† t ngh√®o ho·∫∑c ko ƒëi...\n",
       "6     Phu Khang Tran Ng∆∞·ªùi ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t Ph√πng...\n",
       "7     Phu Khang Tran :V Uh th√¨ \"kh√¥ng mua ƒëc h√†ng th...\n",
       "8     Ng∆∞·ªùi ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t Ph√πng B·∫£o , mua b·∫£n ...\n",
       "9     Phu Khang Tran Th√¨ t√¥i ƒë√¢u c√≥ n√≥i l√† b·∫£n quy·ªÅn...\n",
       "10    Ph√πng B·∫£o B·∫°n ra nh√† s√°ch mua m·∫•y b·ªô manga har...\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.loc[0:10, 'Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c21d6d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't deny that many of them used to watch and read a lot, including me back then. Now, whenever I see my favorite manga series, I want to buy the merchandise to support the author.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_text_with_ollama(df_comments.loc[0, 'Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c5ad78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't deny that many of them used to watch pirated content, including me back then. Now, when I look at my favorite manga series, I want to buy the official merchandise to support the author.\",\n",
       " 'Here is the translation:\\n\\n\"I\\'m a pirate. I don\\'t have money/language conditions, so I just read pirate stuff and accept it, no need to think about why, just draw conclusions and feel more understood.\"',\n",
       " 'Here is the translation:\\n\\n\"I play pirated games when I don\\'t have money, but when I have the means, I buy the game on Steam. It\\'s like that, I would even buy the paper version of it if it\\'s a set I like.\"',\n",
       " 'Here is the translation:\\n\\n\"I spent money to buy a story to support the copyright and was scolded by a few people as stupid. In fact, many people read pirated versions, but those who read original stories have never seen anyone complaining.\"',\n",
       " \"Uyen Nha has enough money and awareness to buy a copyright then of course she's not stupid enough to be superior:\",\n",
       " \"Reading pirated content and just accepting it as being poor or not buying genuine products is okay, but many don't understand how many people can truly show their superiority when they violate the law.\",\n",
       " \"Here is the translation:\\n\\nPhu Khang Tran is the biggest contributor. Isn't that so? Is it poor with no money to buy real goods? Are there counterfeit products without copyright, huh?\",\n",
       " 'Phu Khang Tran: As for that, \"can\\'t buy real goods\" is just an extension of the meaning, becoming \"can\\'t buy real goods with a translation\".',\n",
       " 'Here is the translated text:\\n\\n\"The person who contributes the most is Ph√πng B·∫£o, I buy the original Japanese version, the English translation, and the Vietnamese translation, I\\'ve bought them all already. But then those stories want to read the translation, it\\'s slow in English or Vietnamese, sometimes half a year, sometimes 5-10 years. Anyway, don\\'t pirate with buying the original, there\\'s no point in complaining about the translated version\\'s copyright.\"',\n",
       " \"Here is the translation:\\n\\nPhu Khang Tran said that I don't say that translating into Vietnamese is better than nothing. I just say it's okay if I'm not good at it, but if what I do violates the original content, then it's pointless and useless anyway.\",\n",
       " 'Here is the translation:\\n\\n\"Phung\\'s friend goes to a bookstore to buy some harem manga in Vietnamese translation, haha!\"',\n",
       " 'Here is the translation:\\n\\n\"H·ªì Xu√¢n Ki√™n is in the category \\'don\\'t buy anything\\' because there\\'s nothing to buy.\"',\n",
       " 'A part is some sets that are not licensed by Vietnamese copyright units, specifically like some bloody or NSFW sets, hard to pass the censorship.',\n",
       " 'Long Duy is counting on someone from Japan to publish it for him in the future (but probably will take a long time).',\n",
       " 'Here is the translated text:\\n\\n\"The story can be pirated, but games cannot be cracked. Now there\\'s no platform for free licensed games to experience, and playing crack is more harmful than beneficial. It\\'s harmful because Vietnam gets a bad reputation, leading to IP blocking, malware installation, and no official Vietnamese language support from developers for our market.\"',\n",
       " 'I would like to ask for a favor from you with Mr.',\n",
       " 'Here is the translated text:\\n\\n\"If you want to download a game, I can suggest some reputable websites, first being Epic Games because it offers free games every week so you can get them from there... If you want to play hot games or specific ones right away, you can go to FitGirl or Pirate Bay... and download. If you don\\'t know English, you can use Vietnamese web machines like LND, DMH, THD...... If you\\'re determined to download from another source like RevoltG or buy a key from DivineShop, I advise you to just play the cracked version instead, and if you have money, support the author on Steam, that\\'s the most reliable way.\"',\n",
       " 'Here is the translated text:\\n\\n\"L√™ Quang To·∫£n now lets his brother make a big app like we see how his brother makes it so that there are many keys. What\\'s the point of going to link visa into all those accounts and logging in and out hundreds, thousands of times just to buy one game?\"',\n",
       " \"Even if Steam's account is banned, they're the ones who lose, not us. In reality, many people have this kind of thinking. They're wrong from a legal perspective, but it's their game with copyright and they paid for it, so it's not ours to take. Playing cracked games doesn't reflect our reputation, it reflects Vietnam's reputation instead. It's because of this kind of thinking that 90% of Japanese games auto-ban IPs from VN, whether you understand or not.\",\n",
       " 'Here is the translated text:\\n\\n\"I\\'m L√™ Quang To·∫£n, the author of Vong Hi?. If you say that, I\\'ll take it. I\\'d rather play crack to earn some money than help someone else buy a meal for $100. And as for keys, it\\'s hard to get them, right? There are only keys and nothing else... playing crack makes me have money, and I support the author through steam. If I spend my ultimate on full game, I can\\'t support the author anymore. Poor people receive poor things, and if we do something through a third party, it\\'s just a bunch of nonsense.\"',\n",
       " \"Here is the translation:\\n\\nL√™ Quang To·∫£n doesn't care who's busy or not, he'll stick to this game forever. If he had money, he'd definitely want to own it himself and wouldn't want to share it with anyone else.\",\n",
       " \"Here is the translated text:\\n\\nThe author Vong Hi doesn't know if it's new or just waiting for when it falls apart to buy it. Spending a bit of money on an ultimate game until the end of life, thinking there are still people who spend money to buy games on Steam if everyone has that mindset... crack because it's crack itself, so people want to buy the game on Steam if they like it, because if you have a long-term attachment, no one will play pirated versions 50/50 anymore. It's quite worrying when you get infected with a virus. Crack doesn't earn any money, saying it positively is like promoting the game to those who genuinely want to buy it. And that guy who spends $1 and eats $1000000 is just a disgusting creature.\",\n",
       " \"Here is the translation:\\n\\nNguyen Minh Vu says it's quite good, bro. They also provide a translating tool over there.\",\n",
       " 'Here is the translation:\\n\\n\"The author Vong Hi says goodbye, using revoltG then it\\'s better to download a crack instead of bearing the trouble.\"',\n",
       " \"Here is the translated text:\\n\\nSome people just pretend to support you, but in reality, they're just buying their way into your good graces. It's all just a vague gesture that doesn't mean anything. And worse, they might even get infected with viruses after using cracked software and then claim they didn't know what happened. They're the ones who are making a living off of this reputation, but it's like they're trampling on someone else's rice bowl.\",\n",
       " 'Here is the translated text:\\n\\n\"The author Vong Hi says oh no, he understands it that way is wrong, and RevoltG is just like a pirate, especially since it\\'s even worse than a pirate. It\\'s not like GeForce Now or Steam at all. It\\'s just a guy who abandoned his word for a hundred bucks...it has credibility because of the money it eats, so what else can it do? What\\'s the point of installing a virus into it? The author will die from this, and anyone who uses RevoltG will never want to buy games on Steam again. The more they support it, the more they\\'re helping it.\"',\n",
       " \"I finally understand the mistake. Now I'm playing a cracked game and supporting whoever is willing to join me or not. As for RevoltG, it's clear that they spent money to buy it, so they shouldn't take it from pirate websites. Shallow thinking.\",\n",
       " 'Here is the translated text:\\n\\n\"He\\'s protecting it and supporting him to do so, he downloads a crack file that doesn\\'t matter at all. The more he downloads, the happier he\\'ll be doing it, and he\\'ll do even more of it. Who knows what virus or information he gets from his computer during that process.\"',\n",
       " \"The author Vong Hi is just a shallow thinker, he's teaching and playing crack games with 100 people, at least 30 will buy the game if they're satisfied because crack is no different from a reputable review for users, while REVOLTG is like his father-in-law when it only buys one but earns tens of millions...I'm sure that even if he tries to buy its ultimate version, he won't want to buy any game on Steam again until the end of his life.\",\n",
       " 'Here is the translation:\\n\\n\"The author Vong Hi is different, isn\\'t he? I\\'m saying that it\\'s better to get infected with a common virus than to be like that scoundrel who steals someone else\\'s hard work and brings it back to sell.\"',\n",
       " \"In his words, he doesn't know that Steam wants to take a 30% profit from the game.\",\n",
       " 'Here is the translation:\\n\\nThe author Vong Hi eats and has a share, but that thing revolts. He throws one coin to the author and then takes away all the gold! Is he thinking about whether the author makes games or not?',\n",
       " 'Here is the translated text:\\n\\n\"I\\'m fed up with thinking about bananas from now on. It\\'s not just a coincidence that some people crack and show off, right? Even those who revoltG take the key to add it to their account somewhere. It\\'s like falling from heaven for sure. I\\'ll spend some money to buy the ultimate game full version. There are many ideas wanting unlimited, no limits, only a few old folks get sponsored, you know. And even if my Steam account gets banned, I can just throw away all my progress. Those who use revoltG just play games once and then leave it alone for several times in a row. Not losing all progress is lucky.\"',\n",
       " 'Here is the translated text:\\n\\n\"L√™ Quang To·∫£n is the author of Vong Hi Steam. It has a clause prohibiting account sales/rentals. In general, they find ways to circumvent the law to benefit themselves at the expense of all other parties involved. Steam only needs to tighten the screws on one example - just limit login access to 1-2 devices per day and this gang will be done eating üí©. Since there\\'s offline mode login, it still requires going through the account login step, which they can track completely.\"',\n",
       " \"Here is the translated text:\\n\\nThe author Vong Hi and I will say it again: cracking a game is not only an indirect advertisement but also makes players want to buy the game if they find it interesting, because no one would waste their time playing their favorite game with cracks, as there's nothing left to remember and there's even a risk of viruses. So, cracking is just a way for others to give a genuine review before buying the game. That's understandable, right? Here, it's not just me who knows this; I'll tell you everything... whatever happens, it's from China or somewhere else, but I'm sure it's cheap compared to what we're paying. Okay, got it? When Steam recognizes it, then we can put it on the table for comparison. Otherwise, let's play cracked games for others' sake, and don't be stingy; this is just helping those guys grow stronger.\",\n",
       " 'Here is the translation:\\n\\n\"Advertising for a cracking team, advertising by cracking DLC, or advertising by releasing a new cracked version of it. Advertising by cracking Denuvo for developers.\"',\n",
       " \"Just now I have to admit that even though it's not human-like, but it's not allowing viruses or Trojans to enter and collect user information, which is quite new.\",\n",
       " 'Here is the translated text:\\n\\n\"The author Vong Hi doesn\\'t show off as being smart, because using crack has a high risk and it\\'s just a trial method. Those who want to play their favorite games will buy them on Steam after trying out the crack, not like RevoltG that makes a fuss about nothing. If Steam is a middleman that brings the author\\'s game to players in a fair way, then RevoltG is an unscrupulous middleman when it only buys once and sells to others millions of times, while the game author gets zero.\"',\n",
       " \"The Steam cheat is still playing, breaking the rules, but it's really good. 1 is buying directly, 2 is not playing like that anymore.\",\n",
       " \"Playing games is considered stupid, but buying this kind of stuff at a gray market then it's called extremely foolish.\",\n",
       " 'Here is the translated text:\\n\\n\"Hey, look at this video and you\\'ll know why my boss keeps saying that.))) https://youtu.be/5pd6lpR2CGA?si=NsVbX8godT22LR-t The B√ìC PH·ªêT has changed the KEY GAME market on YouTube forever.\"',\n",
       " \"What's the connection between that and those 'what' questions?\",\n",
       " \"Buy one Steam game instead of a crack, because buying the story is fine, if there's an online sale and it has a translation, then the speed is on par with the world, so there's no reason to look at pirated stories.\",\n",
       " 'Here is the translation:\\n\\n\"Hi·∫øu Tr·∫ßn standard: I\\'ve fully translated a few volumes and it\\'s about to be dropped because there are still copyright issues.\"',\n",
       " \"Here is the translation:\\n\\nShio Kuma Chu Quoc Dat buys the rights to each new volume as soon as it's dead anyway. There are some sets waiting for this year or next month, tired and exhausted about spirit, money isn't lacking.\",\n",
       " 'Here is the translated text:\\n\\n\"Chu Qu·ªëc ƒê·∫°t said briefly that One Piece went to God Valley and sold the new rights nearby on Egg Head üò• Then there are stories no one knows who will take them, and if they don\\'t get taken then heaven helps. Look at the publishers around us lately, all reprinting old series from 15-20 years ago, new stories aren\\'t seen that many. In the past, I bought some comic rights from Comicola with regret, had money but couldn\\'t buy it, it was too hard.\"',\n",
       " \"I'll support the author if there are conditions, otherwise I'll just shut up and use it. That's all, but those wives keep nagging each other.\",\n",
       " 'Here is the translation:\\n\\n\"Number 2 is correct, after spending money to buy a game and being told that I can\\'t download the cracked version, then when I buy a book and am told that I can\\'t read it online...\"',\n",
       " 'Here is the translated text:\\n\\n\"I support piracy in principle, but I still buy stories to support the authors, that\\'s just how life goes. üòá As someone who\\'s frugal like me, I could download a crack and play it, but instead, I\\'d rather spend every penny to buy my favorite game and support the creators, no matter how expensive it is, because I value the effort people put into their work and want to support them even more.\"',\n",
       " 'Here is the translated text:\\n\\n\"It\\'s all about face value, but it\\'s different. The game cracking issue has been resolved smoothly thanks to reputable gaming platforms that are not bound by government or third-party constraints. As for stories, nothing has changed this year or next because the government and publishers have never satisfied foreign readers.\"',\n",
       " 'Here is the translation:\\n\\n\"Tr√≠ L√™ Game crack can disappear because of Steam and it\\'s harder to censor games than stories. Pirated stories are still far away.\"',\n",
       " \"I support original stories and also read pirated stories. I don't play pirated games because I play games normally.\",\n",
       " 'Nguy·ªÖn H·∫£i Thanh means \"Nguyen Hai Thanh\".',\n",
       " 'In addition to being Quang Tu·∫•n, I am also the father of that silly guy Quang Tu·∫•n.',\n",
       " 'Nguyen Hai Thanh May be an image of a text that says \"Holding hands with affection, eating and chatting\".',\n",
       " 'Here is the translation:\\n\\n\"Old games used to be pirated, but now I buy them and don\\'t have time to play. Same with books - before I read pirated copies, I only knew what was good after finishing it. Now that I buy them, I also don\\'t have time to read!\"',\n",
       " 'The biggest issue now is the flood of low-quality products with random quality, and without a foundation of genuine goods, counterfeit products will never thrive on the market, no one wants to spend money to buy a piece of trash back. Vietnamese academic books are very many and of high quality because behind them is a rigorous review system down to each character, whereas entertainment books don\\'t need it, as long as they don\\'t touch politics or moral standards that are vague and laughable. Currently, thanks to the copyright law, a bunch of \"gold\" has been stuffed and sunk to the bottom of the trash book pit.',\n",
       " 'Here is the translation:\\n\\n\"I want to read a real Japanese story, but it\\'s not available here in Vietnam, so I\\'ll just have to settle for this one. And that\\'s not even counting my friends who can\\'t even read Japanese.\"',\n",
       " 'Here is the translated text:\\n\\n\"Personally, I don\\'t think it\\'s necessary to have a pirated version because there are many small streamers who spend money to experience the game for others. Now in VN, we lack online channels that offer legitimate reading rights like Shueisha, so we just choose to read pirated versions.\"',\n",
       " 'Here is the translation:\\n\\n\"Just get it quickly, pirate goods are always fake compared to genuine products. If you\\'ve already played with pirated stuff, just keep quiet and play, don\\'t bother anymore.\"']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[translate_text_with_ollama(c) for c in df_comments.loc[:, 'Comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f9b61",
   "metadata": {},
   "source": [
    "# Extract Selling informations from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53dac0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 170370233dd5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.1 GB                         \u001b[K\n",
      "pulling 72d6f08a42f6: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 624 MB                         \u001b[K\n",
      "pulling 43070e2d4e53: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  11 KB                         \u001b[K\n",
      "pulling c43332387573: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   67 B                         \u001b[K\n",
      "pulling ed11eda7790d: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   30 B                         \u001b[K\n",
      "pulling 7c658f9561e5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  564 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Switch to Large Vision Model \n",
    "!ollama pull llava:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3ad935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "\n",
    "MODEL_NAME = \"llava:7b\" \n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\" \n",
    "IMAGE_PATH = 'data/kimdong1.png'\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Encodes the image file into a Base64 string.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at path: {image_path}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def extract_structured_data_llava(base64_image):\n",
    "    \"\"\"Sends the image and prompt to the local LLaVA model via Ollama.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert data extractor. Analyze the provided e-commerce grid image containing product listings.\n",
    "    Your task is to extract the following fields for all 12 products:\n",
    "    1. name: The title of the product (e.g., 'Th√°m T·ª≠ L·ª´ng Danh Conan').\n",
    "    2. price_vnd: The numerical price in Vietnamese Dong (VND). Remove the currency unit and commas (e.g., 38000).\n",
    "    3. sold_count: The number of items sold. Only include the number (e.g., 20k -> 20000; 80 -> 80). If 'H√†ng m·ªõi v·ªÅ' (New arrival), use 0.\n",
    "\n",
    "    Respond STRICTLY in a JSON array format. Do not include any text, notes, or explanations outside the JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"images\": [base64_image],\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 4096,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"Connecting to Ollama server at {OLLAMA_API_URL} with model {MODEL_NAME}...\")\n",
    "    \n",
    "    try:\n",
    "        # Increase timeout to 10 minutes (600s) for complex multimodal tasks\n",
    "        response = requests.post(OLLAMA_API_URL, json=payload, timeout=600) \n",
    "        response.raise_for_status() \n",
    "        \n",
    "        data = response.json()\n",
    "        raw_json_string = data.get(\"response\", \"\").strip()\n",
    "        \n",
    "        if not raw_json_string:\n",
    "             return None, \"Model returned an empty response.\"\n",
    "\n",
    "        # Clean JSON fences if the model adds them\n",
    "        if raw_json_string.startswith(\"```\"):\n",
    "            raw_json_string = raw_json_string.strip('`').replace(\"json\\n\", \"\").replace(\"JSON\\n\", \"\").strip()\n",
    "        \n",
    "        return json.loads(raw_json_string), None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None, f\"Network/Connection Error: Ensure Ollama is running and accessible. Details: {e}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return None, f\"JSON Decoding Error: Model output was not valid JSON. First 500 chars: \\n{raw_json_string[:500]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"An unexpected error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "419110b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Ollama server at http://localhost:11434/api/generate with model llava:7b...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base64_image = encode_image_to_base64(IMAGE_PATH)\n",
    "if not base64_image:\n",
    "    sys.exit(1)\n",
    "\n",
    "# 2. Extract data using LLaVA\n",
    "extracted_data, error_message = extract_structured_data_llava(base64_image)\n",
    "\n",
    "# 3. Output results\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89567256",
   "metadata": {},
   "source": [
    "## Gemini Free-tier API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c97e9",
   "metadata": {},
   "source": [
    "Google AI Studio gives a free tier API call for Gemini Flash model which is truly effective for images extraction tasks for about 100 images per day. That's enough for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "43858cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from typing import Tuple, Optional, Any, Dict, List\n",
    "import time\n",
    "\n",
    "\n",
    "apiKey = \"AIzaSyD1bhORGVLHJHKOmNMRM001QtTQ_Rcj1do\" \n",
    "MODEL_NAME = \"gemini-2.5-flash-preview-05-20\" \n",
    "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={apiKey}\"\n",
    "IMAGE_PATH = 'data/kimdong1.png' \n",
    "\n",
    "# 1. Image Encoding Function (Required for API submission)\n",
    "def encode_image_to_base64(image_path: str) -> Optional[str]:\n",
    "    \"\"\"Encodes the image file into a Base64 string for the API payload.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            print(\"Image encoded successfully.\")\n",
    "            return base64.b64encode(f.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at path: {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image file: {e}\")\n",
    "        return None\n",
    "# 2. Gemini Extraction Function\n",
    "def extract_structured_data_gemini(base64_image: str) -> Tuple[Optional[List[Dict[str, Any]]], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Sends the image and prompt to the Gemini API, requesting structured JSON output.\n",
    "    Uses exponential backoff for robustness.\n",
    "    \"\"\"\n",
    "    \n",
    "    # UPDATED STRUCTURED EXTRACTION PROMPT: Focuses on extracting small numbers precisely.\n",
    "    prompt = \"\"\"\n",
    "    You are an expert data extractor. Analyze the provided e-commerce grid image containing product listings.\n",
    "    Your task is to extract the following fields for all products visible:\n",
    "    1. name: The full title of the product (e.g., 'Th√°m T·ª≠ L·ª´ng Danh Conan').\n",
    "    2. price_vnd: The numerical price in Vietnamese Dong (VND).\n",
    "    3. sold_count: The numerical count of items sold. Only include the number. Look for the phrase 'ƒê√£ b√°n' or 'b√°n' followed by a number.\n",
    "\n",
    "    Respond STRICTLY in a JSON array format. Do not include any text, notes, or explanations outside the JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\"text\": prompt},\n",
    "                    {\n",
    "                        \"inlineData\": {\n",
    "                            \"mimeType\": \"image/jpeg\",\n",
    "                            \"data\": base64_image\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"generationConfig\": {\n",
    "            \"responseMimeType\": \"application/json\",\n",
    "            \"responseSchema\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\"type\": \"STRING\", \"description\": \"The full product name or title.\"},\n",
    "                        \"price_vnd\": {\"type\": \"INTEGER\", \"description\": \"The numerical price in VND.\"},\n",
    "                        \"sold_count\": {\"type\": \"INTEGER\", \"description\": \"The numerical count of items sold (k converted to 000).\"}\n",
    "                    },\n",
    "                    \"required\": [\"name\", \"price_vnd\", \"sold_count\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"Connecting to Gemini API with model {MODEL_NAME}...\")\n",
    "    \n",
    "    try:\n",
    "        # Exponential backoff for robust API calls\n",
    "        for i in range(5):\n",
    "            try:\n",
    "                response = requests.post(API_URL, json=payload, timeout=60) \n",
    "                response.raise_for_status() \n",
    "                break\n",
    "            except requests.exceptions.RequestException:\n",
    "                if i < 4:\n",
    "                    wait_time = 2 ** i\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        # Extract and parse the generated JSON text\n",
    "        data = response.json()\n",
    "        raw_json_string = data.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '{}').strip()\n",
    "        \n",
    "        return json.loads(raw_json_string), None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None, f\"Network/Connection Error: Ensure internet access and valid API key. Details: {e}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return None, f\"JSON Decoding Error: Model output was not valid JSON.\"\n",
    "    except Exception as e:\n",
    "        return None, f\"An unexpected error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83f2d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image encoded successfully.\n",
      "Connecting to Gemini API with model gemini-2.5-flash-preview-05-20...\n",
      "--------------------------------------------------\n",
      "Data Extraction Successful (Gemini Cloud API):\n",
      "\n",
      "DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price_vnd</th>\n",
       "      <th>sold_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Truy·ªán - Conan (B·∫£n N√¢ng C·∫•p)</td>\n",
       "      <td>35000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Truy·ªán - D·∫•u ·∫§n Ho√†ng Gia</td>\n",
       "      <td>30000</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Truy·ªán - Huy·∫øt Qu·ª∑ H·ªìn Chi·∫øn 2025</td>\n",
       "      <td>35000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Truy·ªán - Th√°m T·ª≠ L·ª´ng Danh Conan - Ti√™n Truy·ªán...</td>\n",
       "      <td>65000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truy·ªán Tranh - Iruma Gia ƒê√°o</td>\n",
       "      <td>25000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Truy·ªán Thanh g∆∞∆°m di·ªát qu·ª∑ ( TB 2025 )</td>\n",
       "      <td>30000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Truy·ªán - Shangri-La Frontier ~ Th·ª£ SƒÉn Game...</td>\n",
       "      <td>40000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truy·ªán - Masamune B√°o Th√π</td>\n",
       "      <td>38000</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Truy·ªán - B·∫£ng X·∫øp H·∫°ng Qu√¢n V∆∞∆°ng</td>\n",
       "      <td>45000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Truy·ªán - Haikyu [1- 45]</td>\n",
       "      <td>40000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Doraemon Movie Story M√†u - Phi√™n B·∫£n...</td>\n",
       "      <td>35000</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Truy·ªán l·∫ª - Spy X Family</td>\n",
       "      <td>30000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Truy·ªán - Ninja Rantaro</td>\n",
       "      <td>40000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Truy·ªán Dragon Ball Super</td>\n",
       "      <td>25000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Truy·ªán - Chu Du ·∫®m Th·ª±c T·∫°i D·ªã Gi·ªõi V·ªõi Kƒ©...</td>\n",
       "      <td>35000</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Truy·ªán - Conan (T1 - T 50) (24 &amp;25)</td>\n",
       "      <td>25000</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Truy·ªán - Bluelock (T√°i B·∫£n 2025)</td>\n",
       "      <td>35000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Truy·ªán Tranh - Gi·ªù tr√† c·ªßa Zero - Th√°m t·ª≠ l·ª´ng...</td>\n",
       "      <td>35000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Truy·ªán - Arya B·∫£n B√™n Th·ªânh Tho·∫£ng L·∫°i Tr√™u...</td>\n",
       "      <td>95000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Truy·ªán [ TB 2024 ] - Shin - C·∫≠u b√© b√∫t ch√¨ [...</td>\n",
       "      <td>25000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  price_vnd  sold_count\n",
       "0                       Truy·ªán - Conan (B·∫£n N√¢ng C·∫•p)      35000       20000\n",
       "1                           Truy·ªán - D·∫•u ·∫§n Ho√†ng Gia      30000       70000\n",
       "2                   Truy·ªán - Huy·∫øt Qu·ª∑ H·ªìn Chi·∫øn 2025      35000        2000\n",
       "3   Truy·ªán - Th√°m T·ª≠ L·ª´ng Danh Conan - Ti√™n Truy·ªán...      65000         999\n",
       "4                        Truy·ªán Tranh - Iruma Gia ƒê√°o      25000        3000\n",
       "5              Truy·ªán Thanh g∆∞∆°m di·ªát qu·ª∑ ( TB 2025 )      30000       20000\n",
       "6      Truy·ªán - Shangri-La Frontier ~ Th·ª£ SƒÉn Game...      40000        6000\n",
       "7                           Truy·ªán - Masamune B√°o Th√π      38000         747\n",
       "8                   Truy·ªán - B·∫£ng X·∫øp H·∫°ng Qu√¢n V∆∞∆°ng      45000        4000\n",
       "9                             Truy·ªán - Haikyu [1- 45]      40000       10000\n",
       "10            Doraemon Movie Story M√†u - Phi√™n B·∫£n...      35000         127\n",
       "11                           Truy·ªán l·∫ª - Spy X Family      30000       20000\n",
       "12                             Truy·ªán - Ninja Rantaro      40000       10000\n",
       "13                           Truy·ªán Dragon Ball Super      25000       10000\n",
       "14      Truy·ªán - Chu Du ·∫®m Th·ª±c T·∫°i D·ªã Gi·ªõi V·ªõi Kƒ©...      35000         299\n",
       "15                Truy·ªán - Conan (T1 - T 50) (24 &25)      25000        8000\n",
       "16                   Truy·ªán - Bluelock (T√°i B·∫£n 2025)      35000        5000\n",
       "17  Truy·ªán Tranh - Gi·ªù tr√† c·ªßa Zero - Th√°m t·ª≠ l·ª´ng...      35000        6000\n",
       "18     Truy·ªán - Arya B·∫£n B√™n Th·ªânh Tho·∫£ng L·∫°i Tr√™u...      95000        4000\n",
       "19    Truy·ªán [ TB 2024 ] - Shin - C·∫≠u b√© b√∫t ch√¨ [...      25000        2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total items extracted: 20\n"
     ]
    }
   ],
   "source": [
    "# --- Execution in Jupyter ---\n",
    "\n",
    "# 1. Encode the image\n",
    "base64_image = encode_image_to_base64(IMAGE_PATH)\n",
    "\n",
    "if base64_image:\n",
    "    # 2. Extract data using Gemini\n",
    "    extracted_data, error_message = extract_structured_data_gemini(base64_image)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if error_message:\n",
    "        print(f\"Extraction Failed: {error_message}\")\n",
    "    elif extracted_data:\n",
    "        print(\"Data Extraction Successful (Gemini Cloud API):\")\n",
    "        \n",
    "        # Display as DataFrame\n",
    "        try:\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "            print(\"\\nDataFrame Preview:\")\n",
    "            display(df) \n",
    "            print(f\"\\nTotal items extracted: {len(df)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert data to DataFrame: {e}\")\n",
    "            print(\"\\nRaw JSON Output:\")\n",
    "            print(json.dumps(extracted_data, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"Extraction failed. Check model output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd5790d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_with_gemini(text: str, max_retries: int = 3) -> str:\n",
    "    \"\"\"Translates Vietnamese text to English using the Gemini API.\"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a specialized translation engine. Translate the following Vietnamese text into clear, modern English. Be concise and provide only the translated text, nothing else. Handle informal Vietnamese slang and terminology gracefully.\"\n",
    "    \n",
    "    payload = {\n",
    "        \"contents\": [{\"parts\": [{\"text\": text}]}],\n",
    "        \"config\": {\"systemInstruction\": {\"parts\": [{\"text\": system_prompt}]}}\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                data=json.dumps(payload),\n",
    "                timeout=30 \n",
    "            )\n",
    "            response.raise_for_status() \n",
    "\n",
    "            result = response.json()\n",
    "            \n",
    "            # Extract the generated text\n",
    "            translated_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'Translation Error').strip()\n",
    "            return translated_text\n",
    "            \n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return \"Translation Error (API Failure)\"\n",
    "        except Exception:\n",
    "            return \"Translation Error (Parsing Failure)\"\n",
    "    return \"Translation Error (Max Retries)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
